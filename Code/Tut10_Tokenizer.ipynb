{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tutorial 10: Tokenizer**\n",
    "\n",
    "This tutorial explains the concept of a tokenizer and demonstrates how to implement and use a basic character-level tokenizer in Python. A tokenizer is a tool that converts text into tokens (smaller units, such as words or characters) and, in some cases, converts those tokens back into text.\n",
    "\n",
    "In this tutorial, we build \n",
    "- 1). A character-level tokenizer that works at the character granularity, encoding each character as a unique token ID and decoding token IDs back to text.\n",
    "- 2). A word-level tokenizer that works at the word granularity, encoding each word as a unique token ID and decoding token IDs back to text.\n",
    "- 3). An n-grams tokenizer that generates sequences of tokens based on an n-grams approach, a fundamental concept in language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_extraction_successful(text):\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content successfully extracted.\n",
      "Sample of Character-level 3-grams: tensor([ 5, 33,  1])\n",
      "Sample of Word-level 2-grams: tensor([ 0, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'As an educator, I often hear students express frustration with university courses, saying they struggle to connect theoretical concepts with real-world applications. Mathematical equations, in particular, can feel overwhelming and disconnected from the core ideas.\\nOn the other hand, I have met students who enjoy working through the mathematical foundations, even preferring this over practical coding tasks.\\nWhen I asked one such student about her reasoning, her perspective was intriguing. She explained that other skills — such as working on real-world projects or writing code to solve practical problems — can easily be learned through online courses. However,solving mathematical equations makes her feel a sense of intellectual superiority over those relying primarily on online resources.\\nI often have to remind students thattheoretical depth and practical skillsare not mutually exclusive but complementary. Understanding the “why behind the math” is essential — not for intellectual superiority, but to build a solid foundation. However, this foundation becomes truly powerful when it’s connected to practical applications that solve real-world problems.\\nFor students who feel disconnected from theory and prefer only hands-on work,\\nUltimately, whether you’re drawn to theory or practice,remember that the most successful learners embrace both.By building a bridge between abstract concepts and practical applications, you prepare yourself not just to succeed, but to lead and innovate in the ever-evolving world of machine learning.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import text_helper\n",
    "from utils.tokenizer import CharTokenizer, WordTokenizer, NGramsTokenizer\n",
    "\n",
    "url = \"https://medium.com/letters-to-my-younger-self-embracing-emotions-and/bridging-theory-and-practice-1b277456400d\"  \n",
    "text = text_helper.extract_medium_post_content(url)\n",
    "if not is_extraction_successful(text):\n",
    "    print(\"Failed to extract valid content from the URL.\")\n",
    "else:\n",
    "    print(\"Content successfully extracted.\")\n",
    "\n",
    "char_tokenizer = CharTokenizer.train_from_text(text)\n",
    "encoded = char_tokenizer.encode(text)\n",
    "\n",
    "ngrams_tokenizer = NGramsTokenizer(n=3)\n",
    "ngrams = ngrams_tokenizer.generate_ngrams(encoded)\n",
    "print(\"Sample of Character-level 3-grams:\", ngrams[0])\n",
    "\n",
    "\n",
    "word_tokenizer = WordTokenizer.train_from_text(text)\n",
    "encoded = word_tokenizer.encode(text)\n",
    "\n",
    "ngrams_tokenizer = NGramsTokenizer(n=2)\n",
    "ngrams = ngrams_tokenizer.generate_ngrams(encoded)\n",
    "print(\"Sample of Word-level 2-grams:\", ngrams[0])\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input sample: [ 5 33  1 15 28  1 19 18 35 17 15 34 29 32  2  1  9  1 29 20 34 19 28  1]\n",
      "output sample: [22 19 15 32  1 33 34 35 18 19 28 34]\n",
      "Input tensor: tensor([17, 15, 34, 29, 32,  2,  1,  9,  1, 29, 20, 34, 19, 28,  1, 22, 19, 15,\n",
      "        32,  1, 33, 34, 35, 18]) and decoded text is 'cator, I often hear stud'\n",
      "Output tensor: tensor([19, 28, 34, 33,  1, 19, 38, 30, 32, 19, 33, 33]) and decoded text is 'ents express'\n",
      "------------------------------\n",
      "Using word level tokenizer\n",
      "input sample: [ 0 14 44  4 88]\n",
      "output sample: [ 65 122  54  61 145]\n",
      "Input tensor: tensor([131,  94,  62,   4,  64]) and decoded text is 'the other hand, I have'\n",
      "Output tensor: tensor([ 83, 122, 144,  46, 147]) and decoded text is 'met students who enjoy working'\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from utils import sequentialdataset as sd\n",
    "import numpy as np\n",
    "\n",
    "#using char-level tokenizer\n",
    "tokenized_text = char_tokenizer.encode(text) \n",
    "dataset = sd.SequentialDataset(tokenized_text, seq_len=24, label_len=12)\n",
    "seq_x, seq_y = dataset[0] \n",
    "print(f\"input sample: {np.round(seq_x.detach().flatten().tolist(),2)}\")\n",
    "print(f\"output sample: {np.round(seq_y.detach().flatten().tolist(),2)}\")\n",
    "\n",
    "\n",
    "sampler = RandomSampler(dataset, replacement=True)\n",
    "dataloader = DataLoader(dataset, batch_size=2, sampler=sampler)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "print(f\"Input tensor: {x[0]} and decoded text is '{char_tokenizer.decode(x[0])}'\")\n",
    "print(f\"Output tensor: {y[0]} and decoded text is '{char_tokenizer.decode(y[0])}'\")\n",
    "\n",
    "\n",
    "## Using word level tokenizer\n",
    "print(\"------------------------------\")\n",
    "print(\"Using word level tokenizer\")\n",
    "tokenized_text = word_tokenizer.encode(text) \n",
    "dataset = sd.SequentialDataset(tokenized_text, seq_len=5, label_len=5)\n",
    "seq_x, seq_y = dataset[0] \n",
    "print(f\"input sample: {np.round(seq_x.detach().flatten().tolist(),2)}\")\n",
    "print(f\"output sample: {np.round(seq_y.detach().flatten().tolist(),2)}\")\n",
    "\n",
    "sampler = RandomSampler(dataset, replacement=True)\n",
    "dataloader = DataLoader(dataset, batch_size=2, sampler=sampler)\n",
    "x, y = next(iter(dataloader))\n",
    "print(f\"Input tensor: {x[0]} and decoded text is '{word_tokenizer.decode(x[0])}'\")\n",
    "print(f\"Output tensor: {y[0]} and decoded text is '{word_tokenizer.decode(y[0])}'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
