{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial 07: Extracting Features from Images\n",
    "\n",
    "In this tutorial, we will explore step-by-step methods for extracting features from images. Feature extraction involves identifying key points, edges, or patterns in an image to enable analysis and recognition tasks. Using Python and libraries like OpenCV and scikit-image, we will cover the following methods:\n",
    "\n",
    "- Color-Based Feature Extraction\n",
    "- Edge Detection\n",
    "- SIFT (Scale-Invariant Feature Transform)\n",
    "- Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_with_mark_points(image, mark_pixels):\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[0])):\n",
    "            if (i, j) in mark_pixels:\n",
    "                print(\"X\", end=\" \")  \n",
    "            else:\n",
    "                print('0', end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image):\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[0])):\n",
    "            print(f\"{image[i][j]:03}\", end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_convolution(image, kernel):    \n",
    "    img_height = len(image)\n",
    "    img_width = len(image[0])\n",
    "    kernel_size = len(kernel)\n",
    "    pad = kernel_size // 2  \n",
    "\n",
    "    output = [[0 for _ in range(img_width)] for _ in range(img_height)]\n",
    "    \n",
    "    for i in range(pad, img_height - pad):\n",
    "        for j in range(pad, img_width - pad):\n",
    "            conv_sum = 0\n",
    "            for m in range(kernel_size):\n",
    "                for n in range(kernel_size):\n",
    "                    pixel = image[i + m - pad][j + n - pad]\n",
    "                    weight = kernel[m][n]\n",
    "                    conv_sum += pixel * weight\n",
    "            output[i][j] = conv_sum\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image as a color image\n",
    "img_path = '../data/sphere/test.png'\n",
    "color_image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "if color_image is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "\n",
    "resized_image = cv2.resize(color_image, (16,16)) \n",
    "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#gray_image = [[int(0.2989 * pixel[0] + 0.587 * pixel[1] + 0.114 * pixel[2]) for pixel in row] for row in resized_image]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "axes[0].imshow(color_image)\n",
    "axes[0].set_title(\"Color Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "\n",
    "axes[1].imshow(gray_image, cmap='gray')\n",
    "axes[1].set_title(\"Grayscale Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(gray_image)\n",
    "\n",
    "avg_pix_value = np.mean(gray_image) # reason for using this thresold: ?? \n",
    "\n",
    "border_pixels = [(i, j) for i in range(len(gray_image)) for j in range(len(gray_image[0])) if gray_image[i][j] < avg_pix_value]\n",
    "#display_image_with_mark_points(gray_image, border_pixels)\n",
    "\n",
    "lowest_x = min(border_pixels, key=lambda coord: coord[0])[0]\n",
    "largest_x = max(border_pixels, key=lambda coord: coord[0])[0]\n",
    "d1 = largest_x - lowest_x\n",
    "\n",
    "lowest_y = min(border_pixels, key=lambda coord: coord[1])[1]\n",
    "largest_y = max(border_pixels, key=lambda coord: coord[1])[1]\n",
    "\n",
    "d2 = largest_y - lowest_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contour_no(gray_img):\n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to improve contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_img = clahe.apply(gray_img)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(enhanced_img, (5, 5), 0)\n",
    "\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_contour(gray_img):\n",
    "    # Apply CLAHE to enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_img = clahe.apply(gray_img)\n",
    "\n",
    "    # Optionally, apply Gaussian Blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(enhanced_img, (5, 5), 0)\n",
    "\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(blurred, 50, 250)\n",
    "\n",
    "    # Perform Morphological Operations\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "\n",
    "    # Apply Opening (erosion followed by dilation)\n",
    "    opened = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Apply Closing (dilation followed by erosion)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours from the processed image\n",
    "    contours, hierarchy = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image as a color image\n",
    "img_path = '../data/sphere/7.jpg'\n",
    "#img_path = './data/pet_images/Golden_retriever_05182.jpg'\n",
    "color_image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "if color_image is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "\n",
    "resized_image = cv2.resize(color_image, (640, 480)) \n",
    "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Extract contours\n",
    "contours = extract_contour(gray_image)\n",
    "contour_image = cv2.drawContours(resized_image.copy(), contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "# Extract SIFT features\n",
    "sift = cv2.SIFT_create(contrastThreshold=0.04, nOctaveLayers=3)\n",
    "keypoints_sift, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "print(f'Number of keypoints detected by SIFT: {len(keypoints_sift)}')\n",
    "\n",
    "\n",
    "# Extract ORB features\n",
    "orb = cv2.ORB_create()\n",
    "orb = cv2.ORB_create(nfeatures=5000)  # Set to detect more keypoints\n",
    "keypoints_orb, descriptors = orb.detectAndCompute(gray_image, None)\n",
    "print(f'Number of keypoints detected by ORB: {len(keypoints_orb)}')\n",
    "\n",
    "img_orb = cv2.drawKeypoints(resized_image.copy(), keypoints_orb, None, flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "img_keypoints = cv2.drawKeypoints(resized_image.copy(), keypoints_sift, None, flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 6))\n",
    "\n",
    "# Display the original color image \n",
    "ax[0, 0].imshow(cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB))\n",
    "ax[0, 0].axis('off')\n",
    "ax[0, 0].set_title('Original Color Image')\n",
    "\n",
    "# Display the contour-detected image \n",
    "ax[0, 1].imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))\n",
    "ax[0, 1].axis('off')\n",
    "ax[0, 1].set_title('Detected Contours')\n",
    "\n",
    "# Display the SIFT features image \n",
    "ax[1, 0].imshow(cv2.cvtColor(img_keypoints, cv2.COLOR_BGR2RGB))\n",
    "ax[1, 0].axis('off')\n",
    "ax[1, 0].set_title('SIFT Features')\n",
    "\n",
    "# Display the ORB features image \n",
    "ax[1, 1].imshow(cv2.cvtColor(img_orb, cv2.COLOR_BGR2RGB))\n",
    "ax[1, 1].axis('off')\n",
    "ax[1, 1].set_title('ORB Features')\n",
    "\n",
    "# Display the images\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sphere_ball(contours,image):  \n",
    "    \n",
    "    min_area = 100  # Minimum area threshold\n",
    "    max_area = 5000  # Maximum area threshold\n",
    "\n",
    "    # Filter contours based on area\n",
    "    filtered_contours = [contour for contour in contours if min_area < cv2.contourArea(contour) < max_area]\n",
    "        \n",
    "    valid_contours = []\n",
    "    for contour in filtered_contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "\n",
    "        if perimeter == 0:  # Avoid division by zero\n",
    "            continue\n",
    "\n",
    "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
    "        \n",
    "        # Check if the contour is roughly circular--> 0.01 < circularity < 2 and \n",
    "        if area > min_area and circularity>0:\n",
    "            valid_contours.append(contour)\n",
    "    \n",
    "\n",
    "    for contour in valid_contours:\n",
    "        cv2.drawContours(image, [contour], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title('Ball Detection')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Load the image as a color image\n",
    "img_path = '../data/sphere/7.jpg'\n",
    "#img_path = './data/pet_images/Golden_retriever_05182.jpg'\n",
    "color_image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "if color_image is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "\n",
    "resized_image = cv2.resize(color_image, (640, 480)) \n",
    "gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Extract contours\n",
    "contours = extract_contour(gray_image)\n",
    "contour_image = cv2.drawContours(resized_image.copy(), contours, -1, (0, 255, 0), 2)\n",
    "check_sphere_ball(contours,resized_image.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def connected_components(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)    \n",
    "    _, binary_image = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    \n",
    "    num_labels, labels = cv2.connectedComponents(binary_image)\n",
    "    output_image = cv2.convertScaleAbs(labels)  \n",
    "   \n",
    "    color_map = np.random.randint(0, 255, (num_labels, 3), dtype=np.uint8)\n",
    "    color_image = np.zeros((labels.shape[0], labels.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        color_image[labels == i] = color_map[i]\n",
    "\n",
    "    return num_labels, labels, color_image\n",
    "\n",
    "\n",
    "img_path = '../data/sphere/7.jpg'\n",
    "image = cv2.imread(img_path)\n",
    "\n",
    "if image is None:\n",
    "    raise Exception(\"Image not found\")\n",
    "\n",
    "num_labels, labels, result_image = connected_components(image)\n",
    "\n",
    "# Show the results\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f\"Connected Components (Total: {num_labels - 1})\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detecting the circle \n",
    "\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 100, param1=130, param2=30, minRadius=50, maxRadius=250)\n",
    "if circles is not None:\n",
    "    for x, y, r in circles[0]:\n",
    "        c = plt.Circle((x, y), r, fill=False, lw=3, ec='C1')\n",
    "        plt.gca().add_patch(c)\n",
    "plt.gcf().set_size_inches((12, 8))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
